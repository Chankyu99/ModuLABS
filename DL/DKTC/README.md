# ğŸ›¡ï¸ DKTC: Korean Threat Conversation Classification
> **Detecting threatening conversations using KLUE-BERT & Pseudo-Labeling Strategy**

[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-yellow)](https://huggingface.co/Kyutron/DKTC_0206)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.13%2B-orange)](https://pytorch.org/)

## ğŸ“Œ Introduction
ì´ í”„ë¡œì íŠ¸ëŠ” ì˜¨ë¼ì¸ ë° ì˜¤í”„ë¼ì¸ì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ í˜•íƒœì˜ ì–¸ì–´ í­ë ¥(í˜‘ë°•, ê°ˆì·¨, ì§ì¥ ë‚´ ê´´ë¡­í˜ ë“±)ì„ ì¡°ê¸°ì— íƒì§€í•˜ê³  ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. 
ì œí•œëœ ë°ì´í„°ì…‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ **KLUE-BERT** ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ **Pseudo-Labeling(ì¤€ì§€ë„ í•™ìŠµ)** ê¸°ë²•ì„ ì ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤.

## ğŸ“Š Dataset & Tasks
í•œêµ­ì–´ ëŒ€í™” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ë‹¤ìŒ 5ê°€ì§€ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤:
* **í˜‘ë°• ëŒ€í™” (Threat)**
* **ê°ˆì·¨ ëŒ€í™” (Extortion)**
* **ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™” (Workplace Harassment)**
* **ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™” (Other Harassment)**
* **ì¼ë°˜ ëŒ€í™” (Normal)**

## ğŸš€ Methodology (Key Strategy)
ë‹¨ìˆœí•œ Fine-tuningì´ë‚˜ Ensemble ë°©ì‹ìœ¼ë¡œëŠ” **F1-Score 0.776**ì˜ ë²½ì„ ë„˜ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤. ì´ë¥¼ ëŒíŒŒí•˜ê¸° ìœ„í•´ **Pseudo-Labeling** ì „ëµì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.

### ğŸ’¡ Teacher-Student Architecture
1.  **Teacher Model:** Stratified K-Fold ì¤‘ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜(Fold 2) ëª¨ë¸ì„ ì„ ì •.
2.  **Pseudo-Labeling:** Test ë°ì´í„°ì— ëŒ€í•´ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³ , **Confidence Score 0.7 ì´ìƒ**ì¸ ê³ ì‹ ë¢°ë„ ë°ì´í„°ë¥¼ ì •ë‹µì§€(Training Set)ì— ì¶”ê°€.
3.  **Student Model:** í™•ì¥ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¬í•™ìŠµ(Retraining)í•˜ì—¬ ê²°ì • ê²½ê³„(Decision Boundary)ë¥¼ ì •êµí™”.

| Experiment | Model | Strategy | Macro F1-Score |
| :--- | :--- | :--- | :--- |
| Baseline | `klue/bert-base` | Simple Fine-tuning | 0.776 |
| Attempt 1 | `klue/bert-base` | 5-Fold Ensemble | 0.726 (ğŸ“‰) |
| **Final** | **`klue/bert-base`** | **Pseudo-Labeling (Conf>0.7)** | **0.802 (ğŸš€ Best)** |

## ğŸ› ï¸ Usage (Inference)
ì´ ëª¨ë¸ì€ Hugging Face Hubì— ì—…ë¡œë“œë˜ì–´ ìˆì–´, ë³„ë„ì˜ ë‹¤ìš´ë¡œë“œ ì—†ì´ `transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì¦‰ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Load Model from Hugging Face
repo_name = "Kyutron/DKTC_0206"
tokenizer = AutoTokenizer.from_pretrained(repo_name)
model = AutoModelForSequenceClassification.from_pretrained(repo_name)

# Sample Inference
text = "ì•¼ ë„ˆ ë‚´ê°€ ì‹œí‚¤ëŠ” ëŒ€ë¡œ ì•ˆ í•˜ë©´ ê°€ë§Œ ì•ˆ ë‘”ë‹¤."
inputs = tokenizer(text, return_tensors="pt")

with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=-1).item()

classes = ['í˜‘ë°•', 'ê°ˆì·¨', 'ì§ì¥ ë‚´ ê´´ë¡­í˜', 'ê¸°íƒ€ ê´´ë¡­í˜', 'ì¼ë°˜']
print(f"Result: {classes[predicted_class]}")
