{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx8-Iezk7Xj9",
        "outputId": "8818d556-e6b2-4c1d-e30b-ba10dd14476b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ÏÇ¨Ïö© Ïû•Ïπò: cuda\n"
          ]
        }
      ],
      "source": [
        "# Íµ¨Îèô ÌôòÍ≤Ω ÌôïÏù∏\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ÏÇ¨Ïö© Ïû•Ïπò: {device}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bfc09feebd94418d9f42c64e118f66bd",
            "79b0d5c0a4b641049db7b7bf63db1385",
            "362bc23b2c744c838d37676b2630c162",
            "3f5f30ce904b4a16af31fb34194757d3",
            "70ab83b7512c4fd484ab0b8ccaeeb854",
            "c0a28cc0b2804b35967c075c1d553973",
            "69e35168b28b482f87a6e146a1d6d89a",
            "2cf121690d7047a0841d6fea6c785bcc",
            "d5c046f57ce142f7b55b2a86416da099",
            "d6ef73c47b17445598dd0d1aa7a21371",
            "0e36fac14e344279b3ab4d9878c86f56",
            "9da98d0307004c9e82667bade6c67419",
            "6c2a312789aa45a781dcf255d06cf56d",
            "04c6ba0e49ae4290acafad2ade1be783",
            "030de2bb3e71440a9868b646b91234c2",
            "310f6c87c7d445d28230df319369b9f4",
            "51b0afabcc6e49c69807fa2b496c78de",
            "5bbbf6d0d05c44f5a5ec998e66fda7c8",
            "0781c3008e39477786cf3d85d9dda0fa",
            "d87bf468d2494f639d925ae7102d77e0",
            "2bf3b9dccb344dcab165eba674c42af0",
            "ae7616ce10304b4f88cf334ce403b42c",
            "167ed5e42ebc458591461f2691a63a42",
            "9321709b96054b3b9fa4718056f1a9d9",
            "3a3f496cbb584cdea3fcdedf864798b6",
            "c0a4f0aa9ecb48d3b06ca475ca3477ed",
            "d699e05fbd964a27b99864e91f2d7e02",
            "54022b00b3b04d1b9f1a60aecce3b5d0",
            "7c3d153c2902488b9b47401a123db35c",
            "1a08b351a1784df7b16601e6c36746ad",
            "eebf58915bcc44828301a49d5c8c9004",
            "aa52f52c20e74f5a8129e62863db7b65",
            "0986b5cc460447c8a1490e87d2f34d42",
            "08afd26bd0694bec8aec9e0d182ad098",
            "35fdff930c774e328ea0d0e78d6ec9c7",
            "1272f6c2e0494d5baabb7452ebffaa56",
            "5e49389d785b42eab2fc3e71fa678048",
            "412105fc02244887ae716be8edd5320f",
            "8fb01bf78ee64cf0a7965223c34f76aa",
            "048414477a124f5891351277f6a30784",
            "0898e7a89cef4162a5a4c484c6e47ed8",
            "030b364699f74775893c7db6dd41dea9",
            "9b7ab08c43704bfb9cc7133c1b57a05a",
            "1d94a24e007549f0a4d904f37464950a",
            "9e24adff845446efb329ffab9d0a13ab",
            "b83a6a7aa0944b05b6b3e8bbe362456a",
            "3b91a47b7b3444e0bdb293f8a012bffc",
            "bf61d87e1f354b6b9dff3d54f36bcb73",
            "6774ade52079405a8ade78898c160c1c",
            "5297a1fa2f2643d8aa9bf978ea7765c0",
            "bd549873f6a245488b20be485994d377",
            "47f90d411e2c40748e8411a479580e54",
            "966666be2cdf46adad8f959cd77e776a",
            "3e031d92fb354805a7c22871604b78c2",
            "871addb3f09f4528b39a1573a40e9133",
            "fd263088492c48e792da0af8739aa847",
            "065bfd5639764eb29032772ef74a1eb2",
            "3c86458e54174259a23910591cea2778",
            "0693caeb56b7425cbc8971b5cbe52da2",
            "3fb626bfa8b64bb29335b803c476766e",
            "0bfbd3ef5fef46e9b4196caaea19cab3",
            "762a80aa144d49689a075852928dc676",
            "571c5f864342434cb14ed453eca7514a",
            "87f94d76c63e4f03aec3d558642fc98d",
            "4441b1b26a02480d8fd2b2d45f8a191c",
            "0e86027e6181467e9a5b36573283c305",
            "d479300176ed4e6db074a18ef4be7d00",
            "9a2ba139c33c4f0789be592e1ec22dc1",
            "1b5f555629ec486baa794c551313200e",
            "c0b10718281f4e5ebce95d40c8b66251",
            "162bafd4fa7b4a6bbaf229d5629343fa",
            "74ab7b9e86a8415b81977626b1ffd105",
            "b1534c85c25e435ab9535391aa74d73b",
            "856f1268bc0147bdadc560fe8224a5f4",
            "bf098f1e710d4049982b4cf07b362a23",
            "385620f472d146e0a7cc68bdd0950d6f",
            "c846e0155c4e4349a63546e4331887fe",
            "dba84b90715a482aad9ed028e1dcc4f5",
            "6a0aa9e3d4044e2bac40cc3576846fba",
            "7f06a81aad22495f981d3485e9e7f8a0",
            "96d8e7f96aec4cdca0ee47dbd1566f7d",
            "bbe7f2e102d9454090352e959d4d6963",
            "d47e5084814f4d16920a4a739fe96a83",
            "f2417bd2c3ea4b318602a09b8a9b9560",
            "167a9bff84bd4200af5946cfce7fae1d",
            "20313efc4cb84efba5f916906734ab99",
            "caa95c320bc14d45b37d5242e29c7663",
            "29205ee248814e18bf71efe057872da5",
            "12e065a7534949ed8167facb1a2d6733",
            "493d9ab62bf64fcba75aed9fb150e119",
            "ab73520eae6c479087d3cb62b4fa146f",
            "5d1d442f5f8345c2896a8151310a1542",
            "0d4786e75914413dbd5575861792cf2f",
            "2bfb6e39a05748cb9aac90af8fd94ee1",
            "198a8dd109d44546b75071029c070bb0",
            "f72e31e7294f4b3391789f7fdd2955e2",
            "348443e439bb4bcb81aab22420b4c081",
            "df728a3ff0894477bcbeb7477387d106",
            "a074a4498b354c8fba3e38aa527430bd",
            "e9588ea2746d4f928a37b44131c883a8",
            "5cc0c634fde5471eaadd4c7e2d972603",
            "1acd4c90fa7a4bd9b9b49640614d2da5",
            "32bd95b5146a44bc9c8180ca67012670",
            "5ac29db3fa91463e9686db2b1ffd1ae8",
            "311f7c3d4a6e44faa33949332095267b",
            "3f2c163f2e9345629425f7abb545f3b1",
            "5ffb66788f034142830472af873e1058",
            "4127ac8fa08b40288c6aca4afd901d82",
            "96b89d2f14034cef8366ff4c9df523ee",
            "16468cb883be43458c51d6842d0df648",
            "a6623536801a49b292b7542cb3cb90a0",
            "c5e6a57a1ecd4dda9c18644ded7c47c4",
            "c2416990063a4c568c4f31cc7d6bc22a",
            "797a9e4d84fd4af78eb214de39ba5ab3",
            "4280618585ff4375a223f1e31321af85",
            "6efe0b7a644e478c92d8f52f9aa33d69",
            "ea61680978f14891ab658ebbf2509bd7",
            "edac537d5a1a4cb083e64a90f6cf5c40",
            "cff4f736c08146b49bdcf1c8cf5eb9bd",
            "8815ed7d57ae4232a8e0196dd631353e",
            "06bd9a0165464094a6eb7b69afafd561",
            "0464335fda4b45559f826e64ee401968",
            "e5cbfd6ab8b545d494dbb08f418e4dc7",
            "a732681c688e4886a9370d20f15d0a35",
            "07c63a33373c459192e3b28491b44163",
            "b0be986b6bf54f0abba00a853f415208",
            "127eeb0423f24937bc377795b7968047",
            "ff5de5f9da1140ddb52862e82ea89aa5",
            "fe0429296c8d427893668c784e073985",
            "13c925f7612b42958352e1225e36d88f",
            "efd5962eb5054365b87ba48aafebaeff",
            "38ad81aa4d774624bc6217f210eb293b",
            "8876148598aa432e90ea57b12ff2f3b0",
            "bf2a3835a72a49d88a26d08c5d2b60d4",
            "f68ec93da63247d7abe4ff6940ad7b6d",
            "87c3e2dac2cf4b32833820a0b63b6b5d",
            "b83bac9e9e9341b6b1871b8c663b72f0",
            "4add3392d6144410a71d67a4ae62e0ff",
            "02da75634de948fc87974491e910e630",
            "5016ac38efae46dd8e002b6f98cff570",
            "10797970ce244e818252723d5e570fc7",
            "2cac3e130d2b4789af2cd70f8430c7c8",
            "21f9cfc898e44447805a5f5ea021c0e0",
            "61caffb28ee44462b33c3e3ff04a4332",
            "51b3bf6fdfe0447db0617859e532184e",
            "5c249042a97748f19a2cb12f409ac28f",
            "2ea530c279ca4a04ab64c8819a8af3b4",
            "799b98f084cb44f5bb85e4552176c8da",
            "5f73c5dc77284d2887ea8549eff5f779",
            "b5cc7c7c5abe46edb45bfbeeee5ba575",
            "cda3e96752274dc1ab26fd69e7d07938",
            "cb7d83c1873e4730b2242a4f983f6879",
            "32aed9112ab54051894d1bf778d8e63d",
            "234c47fe475c4c64aa0ec03713ea8b70"
          ]
        },
        "collapsed": true,
        "id": "iEsdmu6T5nDs",
        "outputId": "9b96677a-5586-4fd2-9800-23d40c91cc23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfc09feebd94418d9f42c64e118f66bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9da98d0307004c9e82667bade6c67419",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "167ed5e42ebc458591461f2691a63a42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08afd26bd0694bec8aec9e0d182ad098",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e24adff845446efb329ffab9d0a13ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Ï†ÄÏû•Îêú Teacher Î™®Îç∏(best_model_fold2.pt) Î°úÎìú Ï§ë...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd263088492c48e792da0af8739aa847",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d479300176ed4e6db074a18ef4be7d00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: klue/bert-base\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "bert.embeddings.position_ids               | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "classifier.bias                            | MISSING    | \n",
            "classifier.weight                          | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üè∑Ô∏è Pseudo-Labeling ÏãúÏûë (Threshold: 0.7)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dba84b90715a482aad9ed028e1dcc4f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìà ÌôïÎ≥¥Îêú Ï∂îÍ∞Ä Îç∞Ïù¥ÌÑ∞: 431Í∞ú\n",
            "üéì Student Î™®Îç∏ ÌïôÏäµ ÏãúÏûë (Epochs: 4)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12e065a7534949ed8167facb1a2d6733",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: klue/bert-base\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "bert.embeddings.position_ids               | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "classifier.bias                            | MISSING    | \n",
            "classifier.weight                          | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n",
            "/tmp/ipython-input-393483618.py:144: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9588ea2746d4f928a37b44131c883a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ep 1:   0%|          | 0/353 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-393483618.py:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6623536801a49b292b7542cb3cb90a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ep 2:   0%|          | 0/353 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0464335fda4b45559f826e64ee401968",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ep 3:   0%|          | 0/353 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8876148598aa432e90ea57b12ff2f3b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ep 4:   0%|          | 0/353 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÅ ÏµúÏ¢Ö Ï∂îÎ°† Ï§ë...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61caffb28ee44462b33c3e3ff04a4332",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéâ 0.802Ï†ê Ïû¨ÌòÑ ÌååÏùº ÏÉùÏÑ± ÏôÑÎ£å: submission_reproduced_0.802.csv\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Description: Fold 2 Î≤†Ïä§Ìä∏ Î™®Îç∏(Teacher)ÏùÑ ÌôúÏö©ÌïòÏó¨ Pseudo-Labeling ÏàòÌñâ ÌõÑ Student Î™®Îç∏ ÌïôÏäµ\n",
        "Best Score: 0.802 (Public Leaderboard)\n",
        "Dependency: best_model_fold2.pt\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import gc\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_cosine_schedule_with_warmup\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ==========================================\n",
        "# 1. ÌôòÍ≤Ω ÏÑ§Ï†ï \n",
        "# ==========================================\n",
        "MODEL_NAME = \"klue/bert-base\"\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "STUDENT_EPOCHS = 4           \n",
        "CONFIDENCE_THRESHOLD = 0.70 \n",
        "TEACHER_PATH = \"best_model_fold2.pt\" # ÏµúÏ¥à Íµ¨ÌòÑ Ïãú Í∞ÄÏû• ÎÜíÏùÄ Ï†êÏàòÎ•º ÎÇ∏ Fold Î™®Îç∏ÏùÑ Îã§Ïãú Íµ¨ÌòÑÌïòÍ∏∞ ÏúÑÌï¥ Î∂àÎü¨Ïò§Í∏∞\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ÏãúÎìú Í≥†Ï†ï\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "# ==========================================\n",
        "# 2. Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ (Ï†ÑÏ≤òÎ¶¨Îäî ÎèôÏùº)\n",
        "# ==========================================\n",
        "\n",
        "# ÌÖçÏä§Ìä∏ ÌÅ¥Î¶¨Îãù Ìï®Ïàò : Í∞úÌñâÎ¨∏Ïûê -> ÌäπÏàò ÌÜ†ÌÅ∞ [SEP] ÌôúÏö©ÏúºÎ°ú ÌôîÏûê Î≥ÄÌôò Ïù∏ÏãùÎ•† UP\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^Í∞Ä-Ìû£a-zA-Z0-9?!\\.,\\s]', '', text)\n",
        "    text = text.replace('\\n', ' [SEP] ')\n",
        "    return text\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# ÏÇ¨Ïö©Îêú Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ \n",
        "\n",
        "class ConversationDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=self.max_len, padding='max_length', add_special_tokens=True)\n",
        "        item = {'input_ids': inputs['input_ids'][0], 'attention_mask': inputs['attention_mask'][0]}\n",
        "        if self.labels is not None: item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "train_df = pd.read_csv('train.csv')\n",
        "normal_df = pd.read_csv('normal_conversation.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ ÌîÑÎ†àÏûÑ Î≥ëÌï© = ÏùºÎ∞ò ÎåÄÌôî Îç∞Ïù¥ÌÑ∞ + ÌõàÎ†® Îç∞Ïù¥ÌÑ∞\n",
        "# ÌÅ¥ÎûòÏä§ Îß§Ìïë\n",
        "\n",
        "normal_df['idx'] = range(train_df['idx'].max() + 1, train_df['idx'].max() + 1 + len(normal_df))\n",
        "normal_df = normal_df[['idx', 'class', 'conversation']]\n",
        "train_df = pd.concat([train_df, normal_df], ignore_index=True)\n",
        "\n",
        "train_df['conversation'] = train_df['conversation'].apply(clean_text)\n",
        "test_df['conversation'] = test_df['conversation'].apply(clean_text)\n",
        "label_dict = {'ÌòëÎ∞ï ÎåÄÌôî':0, 'Í∞àÏ∑® ÎåÄÌôî':1, 'ÏßÅÏû• ÎÇ¥ Í¥¥Î°≠Ìûò ÎåÄÌôî':2, 'Í∏∞ÌÉÄ Í¥¥Î°≠Ìûò ÎåÄÌôî':3, 'ÏùºÎ∞ò ÎåÄÌôî':4}\n",
        "train_df['class'] = train_df['class'].map(label_dict)\n",
        "\n",
        "# ==========================================\n",
        "# 3. Ï†ÄÏû•Îêú Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞ & Pseudo-Labeling\n",
        "# ==========================================\n",
        "print(f\"üìÇ Ï†ÄÏû•Îêú Î™®Îç∏({TEACHER_PATH}) Î°úÎìú Ï§ë...\")\n",
        "\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)\n",
        "teacher_model.load_state_dict(torch.load(TEACHER_PATH))\n",
        "teacher_model.to(device)\n",
        "teacher_model.eval()\n",
        "\n",
        "test_ds = ConversationDataset(test_df['conversation'].tolist(), labels=None, tokenizer=tokenizer, max_len=MAX_LEN)\n",
        "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "pseudo_texts = []\n",
        "pseudo_labels = []\n",
        "\n",
        "print(f\"üè∑Ô∏è Pseudo-Labeling ÏãúÏûë (Threshold: {CONFIDENCE_THRESHOLD})...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Î∞∞Ïπò Îã®ÏúÑÎ°ú Ï∂îÎ°† Î∞è ÌïÑÌÑ∞ÎßÅ\n",
        "    test_texts = test_df['conversation'].tolist()\n",
        "    batch_start = 0\n",
        "\n",
        "    for batch in tqdm(test_loader):\n",
        "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = teacher_model(**inputs)\n",
        "        probs = F.softmax(outputs.logits, dim=-1)\n",
        "        max_probs, preds = torch.max(probs, dim=-1)\n",
        "\n",
        "        max_probs = max_probs.cpu().numpy()\n",
        "        preds = preds.cpu().numpy()\n",
        "\n",
        "        # ÌòÑÏû¨ Î∞∞ÏπòÏùò ÌÖçÏä§Ìä∏ Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "        batch_end = batch_start + len(max_probs)\n",
        "        current_texts = test_texts[batch_start:batch_end]\n",
        "\n",
        "        for i, prob in enumerate(max_probs):\n",
        "            if prob >= CONFIDENCE_THRESHOLD:\n",
        "                pseudo_texts.append(current_texts[i])\n",
        "                pseudo_labels.append(preds[i])\n",
        "\n",
        "        batch_start = batch_end\n",
        "\n",
        "print(f\"üìà ÌôïÎ≥¥Îêú Ï∂îÍ∞Ä Îç∞Ïù¥ÌÑ∞: {len(pseudo_texts)}Í∞ú\")\n",
        "del teacher_model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ==========================================\n",
        "# 4. Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú Ïû¨ÌïôÏäµ (Epoch 4)\n",
        "# ==========================================\n",
        "print(f\"üéì Student Î™®Îç∏ ÌïôÏäµ ÏãúÏûë (Epochs: {STUDENT_EPOCHS})...\")\n",
        "\n",
        "# Pseudo LabelingdÏúºÎ°ú ÏÉùÏÑ±Îêú Îç∞Ïù¥ÌÑ∞ Ìï©ÏπòÍ∏∞\n",
        "final_X = train_df['conversation'].tolist() + pseudo_texts\n",
        "final_y = np.concatenate([train_df['class'].values, np.array(pseudo_labels)])\n",
        "\n",
        "train_ds = ConversationDataset(final_X, final_y, tokenizer, MAX_LEN)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)\n",
        "student_model.to(device)\n",
        "\n",
        "optimizer = AdamW(student_model.parameters(), lr=5e-5)\n",
        "total_steps = len(train_loader) * STUDENT_EPOCHS\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps*0.1), num_training_steps=total_steps)\n",
        "scaler = GradScaler()\n",
        "\n",
        "student_model.train()\n",
        "for epoch in range(STUDENT_EPOCHS):\n",
        "    total_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Ep {epoch+1}\")\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = student_model(**inputs)\n",
        "            loss = outputs.loss\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "# ==========================================\n",
        "# 5. ÏµúÏ¢Ö Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±\n",
        "# ==========================================\n",
        "print(\"üèÅ ÏµúÏ¢Ö Ï∂îÎ°† Ï§ë...\")\n",
        "student_model.eval()\n",
        "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
        "final_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = student_model(**inputs)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "        final_preds.extend(preds)\n",
        "\n",
        "submission = pd.DataFrame({'idx': test_df['idx'], 'target': final_preds})\n",
        "filename = \"submission_reproduced_0.802.csv\"\n",
        "submission.to_csv(filename, index=False)\n",
        "print(f\"üéâ 0.800Ï†ê Ïû¨ÌòÑ ÌååÏùº ÏÉùÏÑ± ÏôÑÎ£å: {filename}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
